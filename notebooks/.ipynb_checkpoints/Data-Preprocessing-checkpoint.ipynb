{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center> Machine Learning Project LifeCyle </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Project LifeCycle\n",
    "\n",
    "<img src=\"../resources/lifeCycle.png\" height=500px width=500px>\n",
    "\n",
    "<br/>\n",
    "\n",
    "The **machine learning project lifecycle** refers to the stages involved in developing and deploying a machine learning model. The project lifecycle typically includes the following stages:\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "- **Problem Definition:** The first step is to define the problem we want to solve. This includes identifying the business or research problem, defining the data requirements, and determining the objectives and metrics for success.\n",
    "<br/>\n",
    "- **Data Collection:** The second step is to collect the data that we will use to build your model. This may involve acquiring data from various sources, including internal and external databases, APIs, and web scraping.\n",
    "<br/>\n",
    "\n",
    "- **Data Cleaning and Preparation:** Once we have collected the data, we need to clean and prepare it for analysis. This involves tasks such as removing duplicates, handling missing data, transforming the data into the appropriate format.\n",
    "<br/>\n",
    "\n",
    "- **Data Analysis and Visualization:** With the data cleaned and prepared, the next step is to analyze and visualize the data to gain insights into the problem we are trying to solve. This may include exploratory data analysis, data visualization, and feature selection.\n",
    "<br/>\n",
    "\n",
    "- **Model Selection and Training:** Once we have a clear understanding of the data, the next step is to select an appropriate machine learning model and train it on the data, before training we need to split the data into training and testing sets.. This step involves evaluating different models and selecting the one that provides the best performance.\n",
    "<br/>\n",
    "\n",
    "- **Model Evaluation:** Once we have trained the model, we need to evaluate its performance on a holdout test set. This involves calculating various metrics, such as mse, rmse, r2,  accuracy, precision, recall, and F1 score.\n",
    "<br/>\n",
    "\n",
    "- **Model Deployment:** If the model performs well, the next step is to deploy it in a production environment. This may involve integrating it with existing systems or building a custom application to provide access to the model.\n",
    "<br/>\n",
    "\n",
    "- **Model Maintenance and Monitoring:** After the model has been deployed, it is important to monitor its performance and ensure that it continues to provide accurate results. This involves tasks such as updating the model as new data becomes available, retraining the model periodically, and monitoring for drift or changes in the data distribution.\n",
    "<br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align='center'>Data Collection</h2>\n",
    "<br>\n",
    "\n",
    "<img src=\"../resources/acq.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align='center'> Data Preprocessing </h2>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"> \n",
    "Data preprocessing is the third step in a machine learning project where we clean and organize the data so that it can be used for analysis and model training. This involves tasks like handling missing values, outliers, and inconsistent data, transforming data to make it suitable for machine learning algorithms, visualizing data to understand patterns. The aim of data preprocessing is to ensure that the data used for machine learning is accurate, reliable, and ready for analysis, and to improve the performance and accuracy of the machine learning models by addressing data quality issues.\n",
    "</div></p>\n",
    "    \n",
    "    \n",
    "<br/>\n",
    "\n",
    "### Data Cleaning\n",
    "\n",
    "- Handling missing values, if any\n",
    "\t- Imputing missing values using simple techniques like mean, median, or mode\n",
    "\t- Removing rows or columns with missing values, if appropriate\n",
    "\n",
    "- Identifying and addressing outliers, if any\n",
    "\t- Using basic statistical techniques to detect outliers\n",
    "\t- Applying appropriate techniques like data transformation or removing outliers, if necessary\n",
    "\n",
    "- Managing inconsistent data, if any\n",
    "\t- Standardizing data format and units\n",
    "\t- Resolving any data inconsistencies or conflicts\n",
    "\n",
    "### Data Transformation\n",
    "\n",
    "- Data normalization\n",
    "\t- Scaling data to a common range to ensure fair comparison\n",
    "- Data encoding\n",
    "\t- Converting categorical data to numerical format for machine learning algorithms\n",
    "\n",
    "### Data Visualization\n",
    "\n",
    "- Using simple data visualization techniques like scatter plots, bar charts, or histograms to explore and understand the data\n",
    "- Identifying patterns, trends, and relationships in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "- **NumPy**\n",
    "- **Pandas**\n",
    "- **Matplotlib and Searrborn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align='center'> NumPy </h2>\n",
    "\n",
    "\n",
    "\n",
    "<p align=\"center\"><div class=\"alert alert-success\" style=\"margin: 20px\"> \n",
    "Numpy is a tool for mathematical computing and data preparation in Python. It can be utilized to perform a number of mathematical operations on arrays such as trigonometric, statistical and algebraic routines. This library provides many useful features including handling n-dimensional arrays, broadcasting, performing operations, data generation, etc., thus, it’s the fundamental package for scientific computing with Python. It also provides a large collection of high-level mathematical functions to operate on arrays.\n",
    "\n",
    "</div></p>\n",
    "\n",
    "<img src=\"../resources/Uses-of-NumPy-1.webp\" height=500px width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation and Implementation\n",
    "\n",
    "!pip3 install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check path and version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concept of scalar, vector , matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumPy Array Creation\n",
    "\n",
    "**1. Built-In Methods**\n",
    "\n",
    "Numpy allows us to use many built-in methods for generating arrays.\n",
    "- `np.array()` - Best method to create a simple array\n",
    "- `np.arange()` – array of arranged values from low to high value\n",
    "- `np.zeros()` – array of zeros with specified shape\n",
    "- `np.ones()` – similarly to zeros, array of ones with specified shape\n",
    "- `np.linspace()` – array of linearly spaced numbers, with specified size\n",
    "- `np.eye()` – two dimensional array with ones on the diagonal, zeros elsewhere\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**2. Random**\n",
    "\n",
    "Numpy allows you to use various functions to produce arrays with random values. To access these functions, first we have to access the `random` function itself. This is done using `np.random`, after which we specify which function we need. Here is a list of the most used random functions and their purpose:\n",
    "- `np.random.rand()` – produce random values in the given shape from 0 to 1\n",
    "- `np.random.randn()` – produce random values with a ‘standard normal’ distribution, from -1 to 1\n",
    "- `np.random.randint()` – produce random numbers from low to high, specified as parameter\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**3. Array Attributes and Methods**\n",
    "\n",
    "Now we will continue with more attributes and methods that can be used on arrays.\n",
    "\n",
    "- `np.reshape()` – changes the shape of an array into the desired shape\n",
    "- `np.shape()` – returns a tuple of the shape of the given array as parameter\n",
    "- `np.dtype()` – returns the data type of the values in the array\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**4. Numpy Indexing and Selection**\n",
    "\n",
    "Here, we will discuss how to select element or groups of elements from an array and change them. There are two methods are used to perform these operations\n",
    "\n",
    "- `Indexing` – pick one or more elements from an array\n",
    "- `Broadcasting` – changing values within an index range\n",
    "\n",
    "<br>\n",
    "\n",
    "**5. Numpy Operations**\n",
    "\n",
    "We can perform different types of operations on NumPy arrays. What this means is we can sum, subtract, multiply or divide the values inside our array, even do things like taking the square root. Below is a list of what we will discuss in this lecture.\n",
    "\n",
    "- `Arithmetic Operations` – sum, subtract, multiply, divide on arrays\n",
    "- `Universal Array Functions` – Mathematical operations provided by NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: \n",
    "Create a 4X2 integer array and Prints its attributes.    \n",
    "**Note: The element must be a type of unsigned int16. And print the following Attributes: –**\n",
    "\n",
    "- The shape of an array.\n",
    "- Array dimensions.\n",
    "- The Length of each element of the array in bytes.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Exercise 2: \n",
    "Create a 5X2 integer array from a range between 100 to 200 such that the difference between each element is 10.    \n",
    "**Hint: Use np.arange() and reshape() function.**\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Exercise 3: \n",
    "Following is the provided numPy array. Return array of items by taking the third column from all rows.    \n",
    "**sampleArray = numpy.array([[11 ,22, 33], [44, 55, 66], [77, 88, 99]])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align='center'> Pandas </h2>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<img align=\"center\" width=\"700\" height=\"700\"  src=\"../resources/pandas-apps.png\"  >\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "> Pandas is an open source python library built on top of numpy and provides easy to use data structures and data analysis tools. Pandas has derived its name from panel data system and was developed by wes mckinney in 2008.\n",
    "\n",
    "> Data scientists use pandas for performing various data science tasks starting from downloading, opening, reading and writing files of different file formats like csv, excel, json, html and so on. They load the data set into its data structure called data frame.\n",
    "\n",
    "> A Pandas Dataframe is a 2-dimensional labeled data structure (like SQL table) with heterogeneously typed columns, having both a row and a column index.\n",
    "\n",
    "> After the data is loaded in a data frame data scientists perform a various data manipulation tasks like filtering and modifying data based on multiple conditions cutting splitting merging sorting scaling pivoting and aggregating of data.\n",
    "\n",
    "> Data cleaning is done to enhance the data accuracy and integrity by identifying and removing null values duplicates and outliers.\n",
    "\n",
    "> Data wrangling actually transforms the data structurally to appropriate format and makes it ready to be used by the machine learning engineers so that they can apply appropriate machine learning models or algorithm on that data set for training validating and testing purposes.\n",
    "\n",
    "\n",
    "<img align=\"center\" width=\"400\" height=\"400\"  src=\"../resources/pandas1.png\"  >\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anatomy of a Dataframe\n",
    "<img align=\"center\" width=\"800\" height=\"500\"  src=\"../resources/dataframe.webp\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anatomy of a Series\n",
    "\n",
    "<img align=\"center\" width=\"500\" height=\"600\"  src=\"../resources/series-anatomy.png\"  >\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installation and Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path and version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series Introduction\n",
    "\n",
    "1. **Creating a Series**\n",
    "    - From Python List\n",
    "    - From NumPy Arrays\n",
    "    - From Python Dictionary\n",
    "    - From a scalar value\n",
    "    - Creating empty series object\n",
    "2. **Attributes of a Pandas Series**\n",
    "3. **Understanding Index in a Series and its usage**\n",
    "    - Identification\n",
    "    - Selection/Filtering/Subsetting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Introduction\n",
    "\n",
    "1. **Creating Dataframe**\n",
    "    - An empty dataframe\n",
    "    - Two-Dimensional NumPy Array\n",
    "    - Dictionary of Python Lists\n",
    "    - Dictionary of Panda Series\n",
    "2. **Attributes of a Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handling with Pandas..\n",
    "\n",
    "- **Data Reading** : Reading from a csv or an excel – Pandas provide two functions – read_csv() and read_excel() to read data from a csv and an excel file respectively. Command can be used as follows.\n",
    "\n",
    "- **Viewing data** – Viewing data from a data frame can be done by three ways\n",
    " >- using the data frame’s name – returns the top and bottom 5 rows in the data frame.\n",
    " >- using dataframe.head() function\n",
    " >- using dataframe.tail() function\n",
    "\n",
    "- **Data Overview** : To see more details on the data frame, the `info()` function can be used. info() gives an idea about what datatype each series in a data frame points to.\n",
    "\n",
    "- The following functions are used to find the unique entries within a series/column in a data frame.\n",
    " >- datafame.unique() – returns the unique values\n",
    " >- dataframe.nunique() – returns the count of unique values\n",
    " >- dataframe.value_counts() – returns the frequency of each of the categories in the column\n",
    "\n",
    "- In our example, the titanic dataset contains a column called `Survived` which tells if the particular passenger survived the tragedy. Since this value could only be either 0 or 1, we can convert the data type from integer to object.\n",
    " >- `dataframe.astype()` is the function which lets us do the conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All statistical functions\n",
    "- `count()` : Returns the number of times an element/data has occurred (non-null)\n",
    "- `sum()`\t: Returns sum of all values\n",
    "- `mean()` : Returns the average of all values\n",
    "- `median()` : Returns the median of all values\n",
    "- `mode()` : Returns the mode\n",
    "- `std()`\t: Returns the standard deviation\n",
    "- `min()`\t: Returns the minimum of all values\n",
    "- `max()`\t: Returns the maximum of all values\n",
    "- `abs()`\t: Returns the absolute value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean: \n",
    "\n",
    "- The mean, also known as the average, is the sum of all values in a dataset divided by the number of values. It is a measure of central tendency that represents the average value of the data.\n",
    "\n",
    "**Example:** \n",
    "- Consider the following dataset of ages (in years) of a group of individuals: 20, 25, 30, 35, 40. The mean of this dataset would be (20 + 25 + 30 + 35 + 40) / 5 = 30 years.\n",
    "\n",
    "**Usage:** \n",
    "- Mean is commonly used to calculate the central tendency of data and provide an overall measure of the average value. It is widely used in statistics, data analysis, and machine learning to understand the typical or average value of a dataset.\n",
    "\n",
    "**Value:** \n",
    "- The mean can be affected by extreme values, also known as outliers, and may not be an appropriate measure of central tendency when dealing with skewed data or data with outliers. A smaller mean value indicates that the values in the dataset are on average smaller, while a greater mean value indicates that the values in the dataset are on average greater.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median:\n",
    "\n",
    "- The median is the middle value in a dataset when it is arranged in ascending or descending order. It is a measure of central tendency that represents the middle value that separates the data into two equal halves.\n",
    "\n",
    "**Example:** \n",
    "    \n",
    "- Consider the same dataset of ages (in years) as in the previous example: 20, 25, 30, 35, 40. The median of this dataset would be 30, as it is the middle value when the dataset is arranged in ascending order.\n",
    "\n",
    "**Usage:**\n",
    "    \n",
    "- Median is commonly used when dealing with datasets that have extreme values or are skewed, as it is less affected by outliers compared to the mean. It is also used when the dataset is not normally distributed or when the data does not follow a symmetrical pattern.\n",
    "\n",
    "\n",
    "**Value:**\n",
    "- The median is not affected by extreme values and may be more appropriate than the mean when dealing with skewed data or data with outliers. It represents the central value that separates the dataset into two equal halves. There is no notion of a smaller or greater median value, as it represents the middle value of the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Variance: \n",
    "- Variance is a measure of how much the values in a dataset deviate from the mean. It is the average of the squared differences between each value and the mean.\n",
    "\n",
    "**Example:** \n",
    "- Consider the following dataset of exam scores: 80, 85, 90, 95, 100. The mean of this dataset is 90. The variance can be calculated as ((80 - 90)^2 + (85 - 90)^2 + (90 - 90)^2 + (95 - 90)^2 + (100 - 90)^2) / 5 = 100.\n",
    "\n",
    "**Usage:** \n",
    "- Variance is commonly used to measure the spread or variability of data points around the mean. It provides a quantitative measure of how much the data points deviate from the mean, indicating the extent of variation in the dataset.\n",
    "\n",
    "\n",
    "**Value:**\n",
    "\n",
    "- A smaller variance value indicates that the data points are closer to the mean and have less variability, while a greater variance value indicates that the data points are further from the mean and have higher variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Deviation: \n",
    "\n",
    "- Standard deviation is the square root of the variance and provides a measure of the average amount of variation or dispersion of data points around the mean.\n",
    "\n",
    "**Example:** \n",
    "- Using the same dataset of exam scores as in the previous example, the variance was calculated as 100. The standard deviation can be calculated as the square root of the variance, which is the square root of 100, or 10.\n",
    "\n",
    "**Usage:** \n",
    "- Standard deviation is commonly used as a measure of data dispersion or variability, similar to variance. It provides a more interpretable measure compared to variance, and is often used in statistical analysis and machine learning to understand the spread or variability of data points within a dataset.\n",
    "\n",
    "**Smaller or Greater Value:** \n",
    "- A smaller value of standard deviation indicates less variability or dispersion of data points around the mean, which can be considered \"good\" in some cases as it suggests that the data points are closer to the mean and the dataset is more consistent. On the other hand, a greater value of standard deviation indicates higher variability or dispersion of data points around the mean, which can be considered \"bad\" in some cases as it suggests that the dataset is more spread out and less consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "- The aggregation function can be applied against a single or more column. You can either apply the same aggregate function across various columns or different aggregate functions across various columns.\n",
    "- Syntax : \n",
    " >- DataFrame.aggregate(self, func, axis=0, *args, ***kwargs)\n",
    " \n",
    "<img src=\"../resources/pandas-agg-func.png\" height=400px width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
